name: Test on GPU

on:
  push:
    branches: [main, released]
  pull_request:
    branches: [main, released]

env:
  PYTHON_VERSION: "3.12"
  UV_VERSION: "0.5.10"

jobs:
  test:
    runs-on:
      - codebuild-pamiq-core-linux-gpu-runner-${{ github.run_id }}-${{ github.run_attempt }}
    strategy:
      fail-fast: false

    steps:
      - name: Check OS
        run: cat /etc/os-release
      - name: Check NVIDIA Driver Version File
        run: |
          NVIDIA_VERSION_FILE="/proc/driver/nvidia/version"
          if [ -f "$NVIDIA_VERSION_FILE" ]; then
            echo "NVIDIA driver version file found:"
            cat "$NVIDIA_VERSION_FILE"
          else
            echo "::error::NVIDIA driver version file not found at $NVIDIA_VERSION_FILE"
            echo "This self-hosted runner does not appear to have NVIDIA GPU drivers installed."
            exit 1
          fi

      - uses: actions/checkout@v4

      - name: Install uv and set the python version
        uses: astral-sh/setup-uv@v4
        with:
          version: ${{ env.UV_VERSION }}
          python-version: ${{ env.PYTHON_VERSION }}
          enable-cache: true

      - name: Install cuda
        run: |
          wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
          sudo dpkg -i cuda-keyring_1.1-1_all.deb
          sudo apt-get update
          sudo apt-get -y install cuda-toolkit-12-8
      - name: Install dependencies
        run: uv sync --extra torch

      - name: Diagnose CUDA setup
        run: |
          echo "=== CUDA Device Information ==="
          ls -la /dev/nvidia* || echo "No NVIDIA devices found in /dev"

          echo "=== Environment Variables ==="
          env | grep -i cuda || echo "No CUDA-related environment variables found"

          echo "=== PyTorch CUDA Configuration ==="
          uv run python -c "import torch; print(f'PyTorch version: {torch.__version__}')"
          uv run python -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"
          uv run python -c "import torch; print(f'CUDA compiled version: {torch.version.cuda}')"
          uv run python -c "import torch; print(f'CUDNN version: {torch.backends.cudnn.version() if torch.backends.cudnn.is_available() else \"Not available\"}')"

          echo "=== Python Error Information ==="
          uv run python -c "
          import torch
          try:
              if not torch.cuda.is_available():
                  print('CUDA not available, detailed debugging:')
                  import os
                  print(f'- CUDA_VISIBLE_DEVICES: {os.environ.get(\"CUDA_VISIBLE_DEVICES\", \"Not set\")}')
                  # Check if NVIDIA CUDA Driver libraries are loaded in memory
                  try:
                      import ctypes
                      ctypes.CDLL('libcuda.so.1')
                      print('- libcuda.so.1 can be loaded')
                  except OSError as e:
                      print(f'- Failed to load libcuda.so.1: {e}')
                  # Check if PyTorch can see any CUDA devices
                  print(f'- NVIDIA Driver count: {torch.cuda.device_count()}')
          except Exception as e:
              print(f'Exception during diagnostics: {e}')
          "

          # Exit with error if CUDA is not available
          CUDA_AVAILABLE=$(uv run python -c "import torch; print(torch.cuda.is_available())")
          if [ "$CUDA_AVAILABLE" != "True" ]; then
            echo "::error::PyTorch cannot detect CUDA capability! This runner requires GPU support."
            exit 1
          fi

          # Print GPU info if available
          uv run python -c "
          import torch
          if torch.cuda.is_available():
              print(f'Found {torch.cuda.device_count()} GPU(s)')
              for i in range(torch.cuda.device_count()):
                  print(f'GPU {i}: {torch.cuda.get_device_name(i)}')
          "

      - name: Run pytest
        run: |
          uv run pytest -v --log-level=INFO tests/pamiq_core/torch/
